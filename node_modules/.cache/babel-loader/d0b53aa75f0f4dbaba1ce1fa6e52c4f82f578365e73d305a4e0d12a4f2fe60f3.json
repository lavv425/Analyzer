{"ast":null,"code":"'use strict';\n\nvar __createBinding = this && this.__createBinding || (Object.create ? function (o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  var desc = Object.getOwnPropertyDescriptor(m, k);\n  if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n    desc = {\n      enumerable: true,\n      get: function () {\n        return m[k];\n      }\n    };\n  }\n  Object.defineProperty(o, k2, desc);\n} : function (o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  o[k2] = m[k];\n});\nvar __setModuleDefault = this && this.__setModuleDefault || (Object.create ? function (o, v) {\n  Object.defineProperty(o, \"default\", {\n    enumerable: true,\n    value: v\n  });\n} : function (o, v) {\n  o[\"default\"] = v;\n});\nvar __importStar = this && this.__importStar || function (mod) {\n  if (mod && mod.__esModule) return mod;\n  var result = {};\n  if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n  __setModuleDefault(result, mod);\n  return result;\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Json2Csv = void 0;\nconst doc_path_1 = require(\"doc-path\");\nconst deeks_1 = require(\"deeks\");\nconst constants_1 = require(\"./constants\");\nconst utils = __importStar(require(\"./utils\"));\nconst Json2Csv = function (options) {\n  const wrapDelimiterCheckRegex = new RegExp(options.delimiter.wrap, 'g'),\n    crlfSearchRegex = /\\r?\\n|\\r/,\n    customValueParser = options.parseValue && typeof options.parseValue === 'function' ? options.parseValue : null,\n    expandingWithoutUnwinding = options.expandArrayObjects && !options.unwindArrays,\n    deeksOptions = {\n      arrayIndexesAsKeys: options.arrayIndexesAsKeys,\n      expandNestedObjects: options.expandNestedObjects,\n      expandArrayObjects: expandingWithoutUnwinding,\n      ignoreEmptyArraysWhenExpanding: expandingWithoutUnwinding,\n      escapeNestedDots: true\n    };\n  /** HEADER FIELD FUNCTIONS **/\n  /**\n   * Returns the list of data field names of all documents in the provided list\n   */\n  function getFieldNameList(data) {\n    // If keys weren't specified, then we'll use the list of keys generated by the deeks module\n    return (0, deeks_1.deepKeysFromList)(data, deeksOptions);\n  }\n  /**\n   * Processes the schemas by checking for schema differences, if so desired.\n   * If schema differences are not to be checked, then it resolves the unique\n   * list of field names.\n   */\n  function processSchemas(documentSchemas) {\n    // If the user wants to check for the same schema (regardless of schema ordering)\n    if (options.checkSchemaDifferences) {\n      return checkSchemaDifferences(documentSchemas);\n    } else {\n      // Otherwise, we do not care if the schemas are different, so we should get the unique list of keys\n      const uniqueFieldNames = utils.unique(utils.flatten(documentSchemas));\n      return uniqueFieldNames;\n    }\n  }\n  /**\n   * This function performs the schema difference check, if the user specifies that it should be checked.\n   * If there are no field names, then there are no differences.\n   * Otherwise, we get the first schema and the remaining list of schemas\n   */\n  function checkSchemaDifferences(documentSchemas) {\n    // have multiple documents - ensure only one schema (regardless of field ordering)\n    const firstDocSchema = documentSchemas[0],\n      restOfDocumentSchemas = documentSchemas.slice(1),\n      schemaDifferences = computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas);\n    // If there are schema inconsistencies, throw a schema not the same error\n    if (schemaDifferences) {\n      throw new Error(constants_1.errors.json2csv.notSameSchema);\n    }\n    return firstDocSchema;\n  }\n  /**\n   * Computes the number of schema differences\n   */\n  function computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas) {\n    return restOfDocumentSchemas.reduce((schemaDifferences, documentSchema) => {\n      // If there is a difference between the schemas, increment the counter of schema inconsistencies\n      const numberOfDifferences = utils.computeSchemaDifferences(firstDocSchema, documentSchema).length;\n      return numberOfDifferences > 0 ? schemaDifferences + 1 : schemaDifferences;\n    }, 0);\n  }\n  /**\n   * If so specified, this filters the detected key paths to exclude any keys that have been specified\n   */\n  function filterExcludedKeys(keyPaths) {\n    if (options.excludeKeys) {\n      return keyPaths.filter(keyPath => {\n        for (const excludedKey of options.excludeKeys) {\n          // Only match if the excludedKey appears at the beginning of the string so we don't accidentally match a key farther down in a key path\n          const regex = excludedKey instanceof RegExp ? excludedKey : new RegExp(\"^\".concat(excludedKey));\n          if (excludedKey === keyPath || keyPath.match(regex)) {\n            return false; // Exclude the key\n          }\n        }\n        return true; // Otherwise, include the key\n      });\n    }\n    return keyPaths;\n  }\n  /**\n   * If so specified, this sorts the header field names alphabetically\n   */\n  function sortHeaderFields(fieldNames) {\n    if (options.sortHeader && typeof options.sortHeader === 'function') {\n      return fieldNames.sort(options.sortHeader);\n    } else if (options.sortHeader) {\n      return fieldNames.sort();\n    }\n    return fieldNames;\n  }\n  /**\n   * Trims the header fields, if the user desires them to be trimmed.\n   */\n  function trimHeaderFields(params) {\n    if (options.trimHeaderFields) {\n      params.headerFields = params.headerFields.map(field => field.split('.').map(component => component.trim()).join('.'));\n    }\n    return params;\n  }\n  /**\n   * Wrap the headings, if desired by the user.\n   */\n  function wrapHeaderFields(params) {\n    // only perform this if we are actually prepending the header\n    if (options.prependHeader) {\n      params.headerFields = params.headerFields.map(function (headingKey) {\n        return wrapFieldValueIfNecessary(headingKey);\n      });\n    }\n    return params;\n  }\n  /**\n   * Generates the CSV header string by joining the headerFields by the field delimiter\n   */\n  function generateCsvHeader(params) {\n    // #185 - generate a keys list to avoid finding native Map() methods\n    const fieldTitleMapKeys = Object.keys(options.fieldTitleMap);\n    params.header = params.headerFields.map(function (field) {\n      let headerKey = field;\n      // If a custom field title was provided for this field, use that\n      if (fieldTitleMapKeys.includes(field)) {\n        headerKey = options.fieldTitleMap[field];\n      } else if (!options.escapeHeaderNestedDots) {\n        // Otherwise, if the user doesn't want nested dots in keys to be escaped, then unescape them\n        headerKey = headerKey.replace(/\\\\\\./g, '.');\n      }\n      return wrapFieldValueIfNecessary(headerKey);\n    }).join(options.delimiter.field);\n    return params;\n  }\n  function convertKeysToHeaderFields() {\n    if (!options.keys) return [];\n    return options.keys.map(key => {\n      if (typeof key === 'object' && 'field' in key) {\n        var _key$title;\n        options.fieldTitleMap[key.field] = (_key$title = key.title) !== null && _key$title !== void 0 ? _key$title : key.field;\n        return key.field;\n      }\n      return key;\n    });\n  }\n  function extractWildcardMatchKeys() {\n    if (!options.keys) return [];\n    return options.keys.flatMap(item => {\n      if (typeof item === 'string') {\n        // Exclude plain strings that were passed in options.keys\n        return [];\n      } else if (item !== null && item !== void 0 && item.wildcardMatch) {\n        // Return \"field\" value for objects with wildcardMatch: true\n        return item.field;\n      }\n      // Exclude other objects\n      return [];\n    });\n  }\n  /**\n   * Retrieve the headings for all documents and return it.\n   * This checks that all documents have the same schema.\n   */\n  function retrieveHeaderFields(data) {\n    const wildcardMatchKeys = extractWildcardMatchKeys();\n    const keyStrings = convertKeysToHeaderFields();\n    const fieldNames = getFieldNameList(data);\n    const processed = processSchemas(fieldNames);\n    if (options.keys) {\n      options.keys = keyStrings;\n      const matchedKeys = keyStrings.flatMap(userProvidedKey => {\n        // If this is not a wildcard matched key, then just return and include it in the resulting key list\n        if (!wildcardMatchKeys.includes(userProvidedKey)) {\n          return userProvidedKey;\n        }\n        // Otherwise, identify all detected keys that match with the provided wildcard key:\n        const matches = [];\n        const regex = new RegExp(\"^\".concat(userProvidedKey));\n        for (const detectedKey of processed) {\n          if (userProvidedKey === detectedKey || detectedKey.match(regex)) {\n            matches.push(detectedKey);\n          }\n        }\n        return matches;\n      });\n      if (!options.unwindArrays) {\n        const filtered = filterExcludedKeys(matchedKeys);\n        return sortHeaderFields(filtered);\n      }\n    }\n    const filtered = filterExcludedKeys(processed);\n    return sortHeaderFields(filtered);\n  }\n  /** RECORD FIELD FUNCTIONS **/\n  /**\n   * Unwinds objects in arrays within record objects if the user specifies the\n   * expandArrayObjects option. If not specified, this passes the params\n   * argument through to the next function in the promise chain.\n   *\n   * The `finalPass` parameter is used to trigger one last pass to ensure no more\n   * arrays need to be expanded\n   */\n  function unwindRecordsIfNecessary(params) {\n    let finalPass = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n    if (options.unwindArrays) {\n      const originalRecordsLength = params.records.length;\n      // Unwind each of the documents at the given headerField\n      params.headerFields.forEach(headerField => {\n        params.records = utils.unwind(params.records, headerField);\n      });\n      const headerFields = retrieveHeaderFields(params.records);\n      params.headerFields = headerFields;\n      // If we were able to unwind more arrays, then try unwinding again...\n      if (originalRecordsLength !== params.records.length) {\n        return unwindRecordsIfNecessary(params);\n      }\n      // Otherwise, we didn't unwind any additional arrays, so continue...\n      // Run a final time in case the earlier unwinding exposed additional\n      // arrays to unwind...\n      if (!finalPass) {\n        return unwindRecordsIfNecessary(params, true);\n      }\n      // If keys were provided, set the headerFields back to the provided keys after unwinding:\n      if (options.keys) {\n        const userSelectedFields = convertKeysToHeaderFields();\n        params.headerFields = filterExcludedKeys(userSelectedFields);\n      }\n      return params;\n    }\n    return params;\n  }\n  /**\n   * Main function which handles the processing of a record, or document to be converted to CSV format\n   * This function specifies and performs the necessary operations in the necessary order\n   * in order to obtain the data and convert it to CSV form while maintaining RFC 4180 compliance.\n   * * Order of operations:\n   * - Get fields from provided key list (as array of actual values)\n   * - Convert the values to csv/string representation [possible option here for custom converters?]\n   * - Trim fields\n   * - Determine if they need to be wrapped (& wrap if necessary)\n   * - Combine values for each line (by joining by field delimiter)\n   */\n  function processRecords(params) {\n    params.recordString = params.records.map(record => {\n      // Retrieve data for each of the headerFields from this record\n      const recordFieldData = retrieveRecordFieldData(record, params.headerFields),\n        // Process the data in this record and return the\n        processedRecordData = recordFieldData.map(fieldValue => {\n          fieldValue = trimRecordFieldValue(fieldValue);\n          fieldValue = preventCsvInjection(fieldValue);\n          let stringified = customValueParser ? customValueParser(fieldValue, recordFieldValueToString) : recordFieldValueToString(fieldValue);\n          stringified = wrapFieldValueIfNecessary(stringified);\n          return stringified;\n        });\n      // Join the record data by the field delimiter\n      return generateCsvRowFromRecord(processedRecordData);\n    }).join(options.delimiter.eol);\n    return params;\n  }\n  /**\n   * Helper function intended to process *just* array values when the expandArrayObjects setting is set to true\n   */\n  function processRecordFieldDataForExpandedArrayObject(recordFieldValue) {\n    const filteredRecordFieldValue = utils.removeEmptyFields(recordFieldValue);\n    // If we have an array and it's either empty of full of empty values, then use an empty value representation\n    if (!recordFieldValue.length || !filteredRecordFieldValue.length) {\n      return options.emptyFieldValue || '';\n    } else if (filteredRecordFieldValue.length === 1) {\n      // Otherwise, we have an array of actual values...\n      // Since we are expanding array objects, we will want to key in on values of objects.\n      return filteredRecordFieldValue[0]; // Extract the single value in the array\n    }\n    return recordFieldValue;\n  }\n  /**\n   * Gets all field values from a particular record for the given list of fields\n   */\n  function retrieveRecordFieldData(record, fields) {\n    const recordValues = [];\n    fields.forEach(field => {\n      let recordFieldValue = (0, doc_path_1.evaluatePath)(record, field);\n      if (!utils.isUndefined(options.emptyFieldValue) && utils.isEmptyField(recordFieldValue)) {\n        recordFieldValue = options.emptyFieldValue;\n      } else if (options.expandArrayObjects && Array.isArray(recordFieldValue)) {\n        recordFieldValue = processRecordFieldDataForExpandedArrayObject(recordFieldValue);\n      }\n      recordValues.push(recordFieldValue);\n    });\n    return recordValues;\n  }\n  /**\n   * Converts a record field value to its string representation\n   */\n  function recordFieldValueToString(fieldValue) {\n    const isDate = fieldValue instanceof Date; // store to avoid checking twice\n    if (fieldValue === null || Array.isArray(fieldValue) || typeof fieldValue === 'object' && !isDate) {\n      return JSON.stringify(fieldValue);\n    } else if (typeof fieldValue === 'undefined') {\n      return 'undefined';\n    } else if (isDate && options.useDateIso8601Format) {\n      return fieldValue.toISOString();\n    } else {\n      return !options.useLocaleFormat ? fieldValue.toString() : fieldValue.toLocaleString();\n    }\n  }\n  /**\n   * Trims the record field value, if specified by the user's provided options\n   */\n  function trimRecordFieldValue(fieldValue) {\n    if (options.trimFieldValues) {\n      if (Array.isArray(fieldValue)) {\n        return fieldValue.map(trimRecordFieldValue);\n      } else if (typeof fieldValue === 'string') {\n        return fieldValue.trim();\n      }\n      return fieldValue;\n    }\n    return fieldValue;\n  }\n  /**\n   * Prevent CSV injection on strings if specified by the user's provided options.\n   * Mitigation will be done by ensuring that the first character doesn't being with:\n   * Equals (=), Plus (+), Minus (-), At (@), Tab (0x09), Carriage return (0x0D).\n   * More info: https://owasp.org/www-community/attacks/CSV_Injection\n   */\n  function preventCsvInjection(fieldValue) {\n    if (options.preventCsvInjection) {\n      if (Array.isArray(fieldValue)) {\n        return fieldValue.map(preventCsvInjection);\n      } else if (typeof fieldValue === 'string' && !utils.isNumber(fieldValue)) {\n        return fieldValue.replace(/^[=+\\-@\\t\\r]+/g, '');\n      }\n      return fieldValue;\n    }\n    return fieldValue;\n  }\n  /**\n   * Escapes quotation marks in the field value, if necessary, and appropriately\n   * wraps the record field value if it contains a comma (field delimiter),\n   * quotation mark (wrap delimiter), or a line break (CRLF)\n   */\n  function wrapFieldValueIfNecessary(fieldValue) {\n    const wrapDelimiter = options.delimiter.wrap;\n    // eg. includes quotation marks (default delimiter)\n    if (fieldValue.includes(options.delimiter.wrap)) {\n      // add an additional quotation mark before each quotation mark appearing in the field value\n      fieldValue = fieldValue.replace(wrapDelimiterCheckRegex, wrapDelimiter + wrapDelimiter);\n    }\n    // if the field contains a comma (field delimiter), quotation mark (wrap delimiter), line break, or CRLF\n    //   then enclose it in quotation marks (wrap delimiter)\n    if (fieldValue.includes(options.delimiter.field) || fieldValue.includes(options.delimiter.wrap) || fieldValue.match(crlfSearchRegex) || options.wrapBooleans && (fieldValue === 'true' || fieldValue === 'false')) {\n      // wrap the field's value in a wrap delimiter (quotation marks by default)\n      fieldValue = wrapDelimiter + fieldValue + wrapDelimiter;\n    }\n    return fieldValue;\n  }\n  /**\n   * Generates the CSV record string by joining the field values together by the field delimiter\n   */\n  function generateCsvRowFromRecord(recordFieldValues) {\n    return recordFieldValues.join(options.delimiter.field);\n  }\n  /** CSV COMPONENT COMBINER/FINAL PROCESSOR **/\n  /**\n   * Performs the final CSV construction by combining the fields in the appropriate\n   * order depending on the provided options values and sends the generated CSV\n   * back to the user\n   */\n  function generateCsvFromComponents(params) {\n    const header = params.header,\n      records = params.recordString,\n      // If we are prepending the header, then add an EOL, otherwise just return the records\n      csv = (options.excelBOM ? constants_1.excelBOM : '') + (options.prependHeader ? header + options.delimiter.eol : '') + records;\n    return csv;\n  }\n  /** MAIN CONVERTER FUNCTION **/\n  /**\n   * Internally exported json2csv function\n   */\n  function convert(data) {\n    // Single document, not an array\n    if (utils.isObject(data) && !data.length) {\n      data = [data]; // Convert to an array of the given document\n    }\n    // Retrieve the heading and then generate the CSV with the keys that are identified\n    const headerFields = {\n      headerFields: retrieveHeaderFields(data),\n      records: data,\n      header: '',\n      recordString: ''\n    };\n    const unwinded = unwindRecordsIfNecessary(headerFields);\n    const processed = processRecords(unwinded);\n    const wrapped = wrapHeaderFields(processed);\n    const trimmed = trimHeaderFields(wrapped);\n    const generated = generateCsvHeader(trimmed);\n    return generateCsvFromComponents(generated);\n  }\n  return {\n    convert\n  };\n};\nexports.Json2Csv = Json2Csv;","map":{"version":3,"names":["__createBinding","Object","create","o","m","k","k2","undefined","desc","getOwnPropertyDescriptor","__esModule","writable","configurable","enumerable","get","defineProperty","__setModuleDefault","v","value","__importStar","mod","result","prototype","hasOwnProperty","call","exports","Json2Csv","doc_path_1","require","deeks_1","constants_1","utils","options","wrapDelimiterCheckRegex","RegExp","delimiter","wrap","crlfSearchRegex","customValueParser","parseValue","expandingWithoutUnwinding","expandArrayObjects","unwindArrays","deeksOptions","arrayIndexesAsKeys","expandNestedObjects","ignoreEmptyArraysWhenExpanding","escapeNestedDots","getFieldNameList","data","deepKeysFromList","processSchemas","documentSchemas","checkSchemaDifferences","uniqueFieldNames","unique","flatten","firstDocSchema","restOfDocumentSchemas","slice","schemaDifferences","computeNumberOfSchemaDifferences","Error","errors","json2csv","notSameSchema","reduce","documentSchema","numberOfDifferences","computeSchemaDifferences","length","filterExcludedKeys","keyPaths","excludeKeys","filter","keyPath","excludedKey","regex","concat","match","sortHeaderFields","fieldNames","sortHeader","sort","trimHeaderFields","params","headerFields","map","field","split","component","trim","join","wrapHeaderFields","prependHeader","headingKey","wrapFieldValueIfNecessary","generateCsvHeader","fieldTitleMapKeys","keys","fieldTitleMap","header","headerKey","includes","escapeHeaderNestedDots","replace","convertKeysToHeaderFields","key","_key$title","title","extractWildcardMatchKeys","flatMap","item","wildcardMatch","retrieveHeaderFields","wildcardMatchKeys","keyStrings","processed","matchedKeys","userProvidedKey","matches","detectedKey","push","filtered","unwindRecordsIfNecessary","finalPass","arguments","originalRecordsLength","records","forEach","headerField","unwind","userSelectedFields","processRecords","recordString","record","recordFieldData","retrieveRecordFieldData","processedRecordData","fieldValue","trimRecordFieldValue","preventCsvInjection","stringified","recordFieldValueToString","generateCsvRowFromRecord","eol","processRecordFieldDataForExpandedArrayObject","recordFieldValue","filteredRecordFieldValue","removeEmptyFields","emptyFieldValue","fields","recordValues","evaluatePath","isUndefined","isEmptyField","Array","isArray","isDate","Date","JSON","stringify","useDateIso8601Format","toISOString","useLocaleFormat","toString","toLocaleString","trimFieldValues","isNumber","wrapDelimiter","wrapBooleans","recordFieldValues","generateCsvFromComponents","csv","excelBOM","convert","isObject","unwinded","wrapped","trimmed","generated"],"sources":["/Applications/XAMPP/xamppfiles/htdocs/projects/ticket/analyzer/node_modules/json-2-csv/lib/json2csv.js"],"sourcesContent":["'use strict';\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Json2Csv = void 0;\nconst doc_path_1 = require(\"doc-path\");\nconst deeks_1 = require(\"deeks\");\nconst constants_1 = require(\"./constants\");\nconst utils = __importStar(require(\"./utils\"));\nconst Json2Csv = function (options) {\n    const wrapDelimiterCheckRegex = new RegExp(options.delimiter.wrap, 'g'), crlfSearchRegex = /\\r?\\n|\\r/, customValueParser = options.parseValue && typeof options.parseValue === 'function' ? options.parseValue : null, expandingWithoutUnwinding = options.expandArrayObjects && !options.unwindArrays, deeksOptions = {\n        arrayIndexesAsKeys: options.arrayIndexesAsKeys,\n        expandNestedObjects: options.expandNestedObjects,\n        expandArrayObjects: expandingWithoutUnwinding,\n        ignoreEmptyArraysWhenExpanding: expandingWithoutUnwinding,\n        escapeNestedDots: true,\n    };\n    /** HEADER FIELD FUNCTIONS **/\n    /**\n     * Returns the list of data field names of all documents in the provided list\n     */\n    function getFieldNameList(data) {\n        // If keys weren't specified, then we'll use the list of keys generated by the deeks module\n        return (0, deeks_1.deepKeysFromList)(data, deeksOptions);\n    }\n    /**\n     * Processes the schemas by checking for schema differences, if so desired.\n     * If schema differences are not to be checked, then it resolves the unique\n     * list of field names.\n     */\n    function processSchemas(documentSchemas) {\n        // If the user wants to check for the same schema (regardless of schema ordering)\n        if (options.checkSchemaDifferences) {\n            return checkSchemaDifferences(documentSchemas);\n        }\n        else {\n            // Otherwise, we do not care if the schemas are different, so we should get the unique list of keys\n            const uniqueFieldNames = utils.unique(utils.flatten(documentSchemas));\n            return uniqueFieldNames;\n        }\n    }\n    /**\n     * This function performs the schema difference check, if the user specifies that it should be checked.\n     * If there are no field names, then there are no differences.\n     * Otherwise, we get the first schema and the remaining list of schemas\n     */\n    function checkSchemaDifferences(documentSchemas) {\n        // have multiple documents - ensure only one schema (regardless of field ordering)\n        const firstDocSchema = documentSchemas[0], restOfDocumentSchemas = documentSchemas.slice(1), schemaDifferences = computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas);\n        // If there are schema inconsistencies, throw a schema not the same error\n        if (schemaDifferences) {\n            throw new Error(constants_1.errors.json2csv.notSameSchema);\n        }\n        return firstDocSchema;\n    }\n    /**\n     * Computes the number of schema differences\n     */\n    function computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas) {\n        return restOfDocumentSchemas.reduce((schemaDifferences, documentSchema) => {\n            // If there is a difference between the schemas, increment the counter of schema inconsistencies\n            const numberOfDifferences = utils.computeSchemaDifferences(firstDocSchema, documentSchema).length;\n            return numberOfDifferences > 0\n                ? schemaDifferences + 1\n                : schemaDifferences;\n        }, 0);\n    }\n    /**\n     * If so specified, this filters the detected key paths to exclude any keys that have been specified\n     */\n    function filterExcludedKeys(keyPaths) {\n        if (options.excludeKeys) {\n            return keyPaths.filter((keyPath) => {\n                for (const excludedKey of options.excludeKeys) {\n                    // Only match if the excludedKey appears at the beginning of the string so we don't accidentally match a key farther down in a key path\n                    const regex = excludedKey instanceof RegExp ? excludedKey : new RegExp(`^${excludedKey}`);\n                    if (excludedKey === keyPath || keyPath.match(regex)) {\n                        return false; // Exclude the key\n                    }\n                }\n                return true; // Otherwise, include the key\n            });\n        }\n        return keyPaths;\n    }\n    /**\n     * If so specified, this sorts the header field names alphabetically\n     */\n    function sortHeaderFields(fieldNames) {\n        if (options.sortHeader && typeof options.sortHeader === 'function') {\n            return fieldNames.sort(options.sortHeader);\n        }\n        else if (options.sortHeader) {\n            return fieldNames.sort();\n        }\n        return fieldNames;\n    }\n    /**\n     * Trims the header fields, if the user desires them to be trimmed.\n     */\n    function trimHeaderFields(params) {\n        if (options.trimHeaderFields) {\n            params.headerFields = params.headerFields.map((field) => field.split('.')\n                .map((component) => component.trim())\n                .join('.'));\n        }\n        return params;\n    }\n    /**\n     * Wrap the headings, if desired by the user.\n     */\n    function wrapHeaderFields(params) {\n        // only perform this if we are actually prepending the header\n        if (options.prependHeader) {\n            params.headerFields = params.headerFields.map(function (headingKey) {\n                return wrapFieldValueIfNecessary(headingKey);\n            });\n        }\n        return params;\n    }\n    /**\n     * Generates the CSV header string by joining the headerFields by the field delimiter\n     */\n    function generateCsvHeader(params) {\n        // #185 - generate a keys list to avoid finding native Map() methods\n        const fieldTitleMapKeys = Object.keys(options.fieldTitleMap);\n        params.header = params.headerFields\n            .map(function (field) {\n            let headerKey = field;\n            // If a custom field title was provided for this field, use that\n            if (fieldTitleMapKeys.includes(field)) {\n                headerKey = options.fieldTitleMap[field];\n            }\n            else if (!options.escapeHeaderNestedDots) {\n                // Otherwise, if the user doesn't want nested dots in keys to be escaped, then unescape them\n                headerKey = headerKey.replace(/\\\\\\./g, '.');\n            }\n            return wrapFieldValueIfNecessary(headerKey);\n        })\n            .join(options.delimiter.field);\n        return params;\n    }\n    function convertKeysToHeaderFields() {\n        if (!options.keys)\n            return [];\n        return options.keys.map((key) => {\n            if (typeof key === 'object' && 'field' in key) {\n                options.fieldTitleMap[key.field] = key.title ?? key.field;\n                return key.field;\n            }\n            return key;\n        });\n    }\n    function extractWildcardMatchKeys() {\n        if (!options.keys)\n            return [];\n        return options.keys.flatMap(item => {\n            if (typeof item === 'string') {\n                // Exclude plain strings that were passed in options.keys\n                return [];\n            }\n            else if (item?.wildcardMatch) {\n                // Return \"field\" value for objects with wildcardMatch: true\n                return item.field;\n            }\n            // Exclude other objects\n            return [];\n        });\n    }\n    /**\n     * Retrieve the headings for all documents and return it.\n     * This checks that all documents have the same schema.\n     */\n    function retrieveHeaderFields(data) {\n        const wildcardMatchKeys = extractWildcardMatchKeys();\n        const keyStrings = convertKeysToHeaderFields();\n        const fieldNames = getFieldNameList(data);\n        const processed = processSchemas(fieldNames);\n        if (options.keys) {\n            options.keys = keyStrings;\n            const matchedKeys = keyStrings.flatMap((userProvidedKey) => {\n                // If this is not a wildcard matched key, then just return and include it in the resulting key list\n                if (!wildcardMatchKeys.includes(userProvidedKey)) {\n                    return userProvidedKey;\n                }\n                // Otherwise, identify all detected keys that match with the provided wildcard key:\n                const matches = [];\n                const regex = new RegExp(`^${userProvidedKey}`);\n                for (const detectedKey of processed) {\n                    if (userProvidedKey === detectedKey || detectedKey.match(regex)) {\n                        matches.push(detectedKey);\n                    }\n                }\n                return matches;\n            });\n            if (!options.unwindArrays) {\n                const filtered = filterExcludedKeys(matchedKeys);\n                return sortHeaderFields(filtered);\n            }\n        }\n        const filtered = filterExcludedKeys(processed);\n        return sortHeaderFields(filtered);\n    }\n    /** RECORD FIELD FUNCTIONS **/\n    /**\n     * Unwinds objects in arrays within record objects if the user specifies the\n     * expandArrayObjects option. If not specified, this passes the params\n     * argument through to the next function in the promise chain.\n     *\n     * The `finalPass` parameter is used to trigger one last pass to ensure no more\n     * arrays need to be expanded\n     */\n    function unwindRecordsIfNecessary(params, finalPass = false) {\n        if (options.unwindArrays) {\n            const originalRecordsLength = params.records.length;\n            // Unwind each of the documents at the given headerField\n            params.headerFields.forEach((headerField) => {\n                params.records = utils.unwind(params.records, headerField);\n            });\n            const headerFields = retrieveHeaderFields(params.records);\n            params.headerFields = headerFields;\n            // If we were able to unwind more arrays, then try unwinding again...\n            if (originalRecordsLength !== params.records.length) {\n                return unwindRecordsIfNecessary(params);\n            }\n            // Otherwise, we didn't unwind any additional arrays, so continue...\n            // Run a final time in case the earlier unwinding exposed additional\n            // arrays to unwind...\n            if (!finalPass) {\n                return unwindRecordsIfNecessary(params, true);\n            }\n            // If keys were provided, set the headerFields back to the provided keys after unwinding:\n            if (options.keys) {\n                const userSelectedFields = convertKeysToHeaderFields();\n                params.headerFields = filterExcludedKeys(userSelectedFields);\n            }\n            return params;\n        }\n        return params;\n    }\n    /**\n     * Main function which handles the processing of a record, or document to be converted to CSV format\n     * This function specifies and performs the necessary operations in the necessary order\n     * in order to obtain the data and convert it to CSV form while maintaining RFC 4180 compliance.\n     * * Order of operations:\n     * - Get fields from provided key list (as array of actual values)\n     * - Convert the values to csv/string representation [possible option here for custom converters?]\n     * - Trim fields\n     * - Determine if they need to be wrapped (& wrap if necessary)\n     * - Combine values for each line (by joining by field delimiter)\n     */\n    function processRecords(params) {\n        params.recordString = params.records.map((record) => {\n            // Retrieve data for each of the headerFields from this record\n            const recordFieldData = retrieveRecordFieldData(record, params.headerFields), \n            // Process the data in this record and return the\n            processedRecordData = recordFieldData.map((fieldValue) => {\n                fieldValue = trimRecordFieldValue(fieldValue);\n                fieldValue = preventCsvInjection(fieldValue);\n                let stringified = customValueParser ? customValueParser(fieldValue, recordFieldValueToString) : recordFieldValueToString(fieldValue);\n                stringified = wrapFieldValueIfNecessary(stringified);\n                return stringified;\n            });\n            // Join the record data by the field delimiter\n            return generateCsvRowFromRecord(processedRecordData);\n        }).join(options.delimiter.eol);\n        return params;\n    }\n    /**\n     * Helper function intended to process *just* array values when the expandArrayObjects setting is set to true\n     */\n    function processRecordFieldDataForExpandedArrayObject(recordFieldValue) {\n        const filteredRecordFieldValue = utils.removeEmptyFields(recordFieldValue);\n        // If we have an array and it's either empty of full of empty values, then use an empty value representation\n        if (!recordFieldValue.length || !filteredRecordFieldValue.length) {\n            return options.emptyFieldValue || '';\n        }\n        else if (filteredRecordFieldValue.length === 1) {\n            // Otherwise, we have an array of actual values...\n            // Since we are expanding array objects, we will want to key in on values of objects.\n            return filteredRecordFieldValue[0]; // Extract the single value in the array\n        }\n        return recordFieldValue;\n    }\n    /**\n     * Gets all field values from a particular record for the given list of fields\n     */\n    function retrieveRecordFieldData(record, fields) {\n        const recordValues = [];\n        fields.forEach((field) => {\n            let recordFieldValue = (0, doc_path_1.evaluatePath)(record, field);\n            if (!utils.isUndefined(options.emptyFieldValue) && utils.isEmptyField(recordFieldValue)) {\n                recordFieldValue = options.emptyFieldValue;\n            }\n            else if (options.expandArrayObjects && Array.isArray(recordFieldValue)) {\n                recordFieldValue = processRecordFieldDataForExpandedArrayObject(recordFieldValue);\n            }\n            recordValues.push(recordFieldValue);\n        });\n        return recordValues;\n    }\n    /**\n     * Converts a record field value to its string representation\n     */\n    function recordFieldValueToString(fieldValue) {\n        const isDate = fieldValue instanceof Date; // store to avoid checking twice\n        if (fieldValue === null || Array.isArray(fieldValue) || typeof fieldValue === 'object' && !isDate) {\n            return JSON.stringify(fieldValue);\n        }\n        else if (typeof fieldValue === 'undefined') {\n            return 'undefined';\n        }\n        else if (isDate && options.useDateIso8601Format) {\n            return fieldValue.toISOString();\n        }\n        else {\n            return !options.useLocaleFormat ? fieldValue.toString() : fieldValue.toLocaleString();\n        }\n    }\n    /**\n     * Trims the record field value, if specified by the user's provided options\n     */\n    function trimRecordFieldValue(fieldValue) {\n        if (options.trimFieldValues) {\n            if (Array.isArray(fieldValue)) {\n                return fieldValue.map(trimRecordFieldValue);\n            }\n            else if (typeof fieldValue === 'string') {\n                return fieldValue.trim();\n            }\n            return fieldValue;\n        }\n        return fieldValue;\n    }\n    /**\n     * Prevent CSV injection on strings if specified by the user's provided options.\n     * Mitigation will be done by ensuring that the first character doesn't being with:\n     * Equals (=), Plus (+), Minus (-), At (@), Tab (0x09), Carriage return (0x0D).\n     * More info: https://owasp.org/www-community/attacks/CSV_Injection\n     */\n    function preventCsvInjection(fieldValue) {\n        if (options.preventCsvInjection) {\n            if (Array.isArray(fieldValue)) {\n                return fieldValue.map(preventCsvInjection);\n            }\n            else if (typeof fieldValue === 'string' && !utils.isNumber(fieldValue)) {\n                return fieldValue.replace(/^[=+\\-@\\t\\r]+/g, '');\n            }\n            return fieldValue;\n        }\n        return fieldValue;\n    }\n    /**\n     * Escapes quotation marks in the field value, if necessary, and appropriately\n     * wraps the record field value if it contains a comma (field delimiter),\n     * quotation mark (wrap delimiter), or a line break (CRLF)\n     */\n    function wrapFieldValueIfNecessary(fieldValue) {\n        const wrapDelimiter = options.delimiter.wrap;\n        // eg. includes quotation marks (default delimiter)\n        if (fieldValue.includes(options.delimiter.wrap)) {\n            // add an additional quotation mark before each quotation mark appearing in the field value\n            fieldValue = fieldValue.replace(wrapDelimiterCheckRegex, wrapDelimiter + wrapDelimiter);\n        }\n        // if the field contains a comma (field delimiter), quotation mark (wrap delimiter), line break, or CRLF\n        //   then enclose it in quotation marks (wrap delimiter)\n        if (fieldValue.includes(options.delimiter.field) ||\n            fieldValue.includes(options.delimiter.wrap) ||\n            fieldValue.match(crlfSearchRegex) ||\n            options.wrapBooleans && (fieldValue === 'true' || fieldValue === 'false')) {\n            // wrap the field's value in a wrap delimiter (quotation marks by default)\n            fieldValue = wrapDelimiter + fieldValue + wrapDelimiter;\n        }\n        return fieldValue;\n    }\n    /**\n     * Generates the CSV record string by joining the field values together by the field delimiter\n     */\n    function generateCsvRowFromRecord(recordFieldValues) {\n        return recordFieldValues.join(options.delimiter.field);\n    }\n    /** CSV COMPONENT COMBINER/FINAL PROCESSOR **/\n    /**\n     * Performs the final CSV construction by combining the fields in the appropriate\n     * order depending on the provided options values and sends the generated CSV\n     * back to the user\n     */\n    function generateCsvFromComponents(params) {\n        const header = params.header, records = params.recordString, \n        // If we are prepending the header, then add an EOL, otherwise just return the records\n        csv = (options.excelBOM ? constants_1.excelBOM : '') +\n            (options.prependHeader ? header + options.delimiter.eol : '') +\n            records;\n        return csv;\n    }\n    /** MAIN CONVERTER FUNCTION **/\n    /**\n     * Internally exported json2csv function\n     */\n    function convert(data) {\n        // Single document, not an array\n        if (utils.isObject(data) && !data.length) {\n            data = [data]; // Convert to an array of the given document\n        }\n        // Retrieve the heading and then generate the CSV with the keys that are identified\n        const headerFields = {\n            headerFields: retrieveHeaderFields(data),\n            records: data,\n            header: '',\n            recordString: '',\n        };\n        const unwinded = unwindRecordsIfNecessary(headerFields);\n        const processed = processRecords(unwinded);\n        const wrapped = wrapHeaderFields(processed);\n        const trimmed = trimHeaderFields(wrapped);\n        const generated = generateCsvHeader(trimmed);\n        return generateCsvFromComponents(generated);\n    }\n    return {\n        convert,\n    };\n};\nexports.Json2Csv = Json2Csv;\n"],"mappings":"AAAA,YAAY;;AACZ,IAAIA,eAAe,GAAI,IAAI,IAAI,IAAI,CAACA,eAAe,KAAMC,MAAM,CAACC,MAAM,GAAI,UAASC,CAAC,EAAEC,CAAC,EAAEC,CAAC,EAAEC,EAAE,EAAE;EAC5F,IAAIA,EAAE,KAAKC,SAAS,EAAED,EAAE,GAAGD,CAAC;EAC5B,IAAIG,IAAI,GAAGP,MAAM,CAACQ,wBAAwB,CAACL,CAAC,EAAEC,CAAC,CAAC;EAChD,IAAI,CAACG,IAAI,KAAK,KAAK,IAAIA,IAAI,GAAG,CAACJ,CAAC,CAACM,UAAU,GAAGF,IAAI,CAACG,QAAQ,IAAIH,IAAI,CAACI,YAAY,CAAC,EAAE;IACjFJ,IAAI,GAAG;MAAEK,UAAU,EAAE,IAAI;MAAEC,GAAG,EAAE,SAAAA,CAAA,EAAW;QAAE,OAAOV,CAAC,CAACC,CAAC,CAAC;MAAE;IAAE,CAAC;EAC/D;EACAJ,MAAM,CAACc,cAAc,CAACZ,CAAC,EAAEG,EAAE,EAAEE,IAAI,CAAC;AACtC,CAAC,GAAK,UAASL,CAAC,EAAEC,CAAC,EAAEC,CAAC,EAAEC,EAAE,EAAE;EACxB,IAAIA,EAAE,KAAKC,SAAS,EAAED,EAAE,GAAGD,CAAC;EAC5BF,CAAC,CAACG,EAAE,CAAC,GAAGF,CAAC,CAACC,CAAC,CAAC;AAChB,CAAE,CAAC;AACH,IAAIW,kBAAkB,GAAI,IAAI,IAAI,IAAI,CAACA,kBAAkB,KAAMf,MAAM,CAACC,MAAM,GAAI,UAASC,CAAC,EAAEc,CAAC,EAAE;EAC3FhB,MAAM,CAACc,cAAc,CAACZ,CAAC,EAAE,SAAS,EAAE;IAAEU,UAAU,EAAE,IAAI;IAAEK,KAAK,EAAED;EAAE,CAAC,CAAC;AACvE,CAAC,GAAI,UAASd,CAAC,EAAEc,CAAC,EAAE;EAChBd,CAAC,CAAC,SAAS,CAAC,GAAGc,CAAC;AACpB,CAAC,CAAC;AACF,IAAIE,YAAY,GAAI,IAAI,IAAI,IAAI,CAACA,YAAY,IAAK,UAAUC,GAAG,EAAE;EAC7D,IAAIA,GAAG,IAAIA,GAAG,CAACV,UAAU,EAAE,OAAOU,GAAG;EACrC,IAAIC,MAAM,GAAG,CAAC,CAAC;EACf,IAAID,GAAG,IAAI,IAAI,EAAE,KAAK,IAAIf,CAAC,IAAIe,GAAG,EAAE,IAAIf,CAAC,KAAK,SAAS,IAAIJ,MAAM,CAACqB,SAAS,CAACC,cAAc,CAACC,IAAI,CAACJ,GAAG,EAAEf,CAAC,CAAC,EAAEL,eAAe,CAACqB,MAAM,EAAED,GAAG,EAAEf,CAAC,CAAC;EACxIW,kBAAkB,CAACK,MAAM,EAAED,GAAG,CAAC;EAC/B,OAAOC,MAAM;AACjB,CAAC;AACDpB,MAAM,CAACc,cAAc,CAACU,OAAO,EAAE,YAAY,EAAE;EAAEP,KAAK,EAAE;AAAK,CAAC,CAAC;AAC7DO,OAAO,CAACC,QAAQ,GAAG,KAAK,CAAC;AACzB,MAAMC,UAAU,GAAGC,OAAO,CAAC,UAAU,CAAC;AACtC,MAAMC,OAAO,GAAGD,OAAO,CAAC,OAAO,CAAC;AAChC,MAAME,WAAW,GAAGF,OAAO,CAAC,aAAa,CAAC;AAC1C,MAAMG,KAAK,GAAGZ,YAAY,CAACS,OAAO,CAAC,SAAS,CAAC,CAAC;AAC9C,MAAMF,QAAQ,GAAG,SAAAA,CAAUM,OAAO,EAAE;EAChC,MAAMC,uBAAuB,GAAG,IAAIC,MAAM,CAACF,OAAO,CAACG,SAAS,CAACC,IAAI,EAAE,GAAG,CAAC;IAAEC,eAAe,GAAG,UAAU;IAAEC,iBAAiB,GAAGN,OAAO,CAACO,UAAU,IAAI,OAAOP,OAAO,CAACO,UAAU,KAAK,UAAU,GAAGP,OAAO,CAACO,UAAU,GAAG,IAAI;IAAEC,yBAAyB,GAAGR,OAAO,CAACS,kBAAkB,IAAI,CAACT,OAAO,CAACU,YAAY;IAAEC,YAAY,GAAG;MACnTC,kBAAkB,EAAEZ,OAAO,CAACY,kBAAkB;MAC9CC,mBAAmB,EAAEb,OAAO,CAACa,mBAAmB;MAChDJ,kBAAkB,EAAED,yBAAyB;MAC7CM,8BAA8B,EAAEN,yBAAyB;MACzDO,gBAAgB,EAAE;IACtB,CAAC;EACD;EACA;AACJ;AACA;EACI,SAASC,gBAAgBA,CAACC,IAAI,EAAE;IAC5B;IACA,OAAO,CAAC,CAAC,EAAEpB,OAAO,CAACqB,gBAAgB,EAAED,IAAI,EAAEN,YAAY,CAAC;EAC5D;EACA;AACJ;AACA;AACA;AACA;EACI,SAASQ,cAAcA,CAACC,eAAe,EAAE;IACrC;IACA,IAAIpB,OAAO,CAACqB,sBAAsB,EAAE;MAChC,OAAOA,sBAAsB,CAACD,eAAe,CAAC;IAClD,CAAC,MACI;MACD;MACA,MAAME,gBAAgB,GAAGvB,KAAK,CAACwB,MAAM,CAACxB,KAAK,CAACyB,OAAO,CAACJ,eAAe,CAAC,CAAC;MACrE,OAAOE,gBAAgB;IAC3B;EACJ;EACA;AACJ;AACA;AACA;AACA;EACI,SAASD,sBAAsBA,CAACD,eAAe,EAAE;IAC7C;IACA,MAAMK,cAAc,GAAGL,eAAe,CAAC,CAAC,CAAC;MAAEM,qBAAqB,GAAGN,eAAe,CAACO,KAAK,CAAC,CAAC,CAAC;MAAEC,iBAAiB,GAAGC,gCAAgC,CAACJ,cAAc,EAAEC,qBAAqB,CAAC;IACxL;IACA,IAAIE,iBAAiB,EAAE;MACnB,MAAM,IAAIE,KAAK,CAAChC,WAAW,CAACiC,MAAM,CAACC,QAAQ,CAACC,aAAa,CAAC;IAC9D;IACA,OAAOR,cAAc;EACzB;EACA;AACJ;AACA;EACI,SAASI,gCAAgCA,CAACJ,cAAc,EAAEC,qBAAqB,EAAE;IAC7E,OAAOA,qBAAqB,CAACQ,MAAM,CAAC,CAACN,iBAAiB,EAAEO,cAAc,KAAK;MACvE;MACA,MAAMC,mBAAmB,GAAGrC,KAAK,CAACsC,wBAAwB,CAACZ,cAAc,EAAEU,cAAc,CAAC,CAACG,MAAM;MACjG,OAAOF,mBAAmB,GAAG,CAAC,GACxBR,iBAAiB,GAAG,CAAC,GACrBA,iBAAiB;IAC3B,CAAC,EAAE,CAAC,CAAC;EACT;EACA;AACJ;AACA;EACI,SAASW,kBAAkBA,CAACC,QAAQ,EAAE;IAClC,IAAIxC,OAAO,CAACyC,WAAW,EAAE;MACrB,OAAOD,QAAQ,CAACE,MAAM,CAAEC,OAAO,IAAK;QAChC,KAAK,MAAMC,WAAW,IAAI5C,OAAO,CAACyC,WAAW,EAAE;UAC3C;UACA,MAAMI,KAAK,GAAGD,WAAW,YAAY1C,MAAM,GAAG0C,WAAW,GAAG,IAAI1C,MAAM,KAAA4C,MAAA,CAAKF,WAAW,CAAE,CAAC;UACzF,IAAIA,WAAW,KAAKD,OAAO,IAAIA,OAAO,CAACI,KAAK,CAACF,KAAK,CAAC,EAAE;YACjD,OAAO,KAAK,CAAC,CAAC;UAClB;QACJ;QACA,OAAO,IAAI,CAAC,CAAC;MACjB,CAAC,CAAC;IACN;IACA,OAAOL,QAAQ;EACnB;EACA;AACJ;AACA;EACI,SAASQ,gBAAgBA,CAACC,UAAU,EAAE;IAClC,IAAIjD,OAAO,CAACkD,UAAU,IAAI,OAAOlD,OAAO,CAACkD,UAAU,KAAK,UAAU,EAAE;MAChE,OAAOD,UAAU,CAACE,IAAI,CAACnD,OAAO,CAACkD,UAAU,CAAC;IAC9C,CAAC,MACI,IAAIlD,OAAO,CAACkD,UAAU,EAAE;MACzB,OAAOD,UAAU,CAACE,IAAI,CAAC,CAAC;IAC5B;IACA,OAAOF,UAAU;EACrB;EACA;AACJ;AACA;EACI,SAASG,gBAAgBA,CAACC,MAAM,EAAE;IAC9B,IAAIrD,OAAO,CAACoD,gBAAgB,EAAE;MAC1BC,MAAM,CAACC,YAAY,GAAGD,MAAM,CAACC,YAAY,CAACC,GAAG,CAAEC,KAAK,IAAKA,KAAK,CAACC,KAAK,CAAC,GAAG,CAAC,CACpEF,GAAG,CAAEG,SAAS,IAAKA,SAAS,CAACC,IAAI,CAAC,CAAC,CAAC,CACpCC,IAAI,CAAC,GAAG,CAAC,CAAC;IACnB;IACA,OAAOP,MAAM;EACjB;EACA;AACJ;AACA;EACI,SAASQ,gBAAgBA,CAACR,MAAM,EAAE;IAC9B;IACA,IAAIrD,OAAO,CAAC8D,aAAa,EAAE;MACvBT,MAAM,CAACC,YAAY,GAAGD,MAAM,CAACC,YAAY,CAACC,GAAG,CAAC,UAAUQ,UAAU,EAAE;QAChE,OAAOC,yBAAyB,CAACD,UAAU,CAAC;MAChD,CAAC,CAAC;IACN;IACA,OAAOV,MAAM;EACjB;EACA;AACJ;AACA;EACI,SAASY,iBAAiBA,CAACZ,MAAM,EAAE;IAC/B;IACA,MAAMa,iBAAiB,GAAGjG,MAAM,CAACkG,IAAI,CAACnE,OAAO,CAACoE,aAAa,CAAC;IAC5Df,MAAM,CAACgB,MAAM,GAAGhB,MAAM,CAACC,YAAY,CAC9BC,GAAG,CAAC,UAAUC,KAAK,EAAE;MACtB,IAAIc,SAAS,GAAGd,KAAK;MACrB;MACA,IAAIU,iBAAiB,CAACK,QAAQ,CAACf,KAAK,CAAC,EAAE;QACnCc,SAAS,GAAGtE,OAAO,CAACoE,aAAa,CAACZ,KAAK,CAAC;MAC5C,CAAC,MACI,IAAI,CAACxD,OAAO,CAACwE,sBAAsB,EAAE;QACtC;QACAF,SAAS,GAAGA,SAAS,CAACG,OAAO,CAAC,OAAO,EAAE,GAAG,CAAC;MAC/C;MACA,OAAOT,yBAAyB,CAACM,SAAS,CAAC;IAC/C,CAAC,CAAC,CACGV,IAAI,CAAC5D,OAAO,CAACG,SAAS,CAACqD,KAAK,CAAC;IAClC,OAAOH,MAAM;EACjB;EACA,SAASqB,yBAAyBA,CAAA,EAAG;IACjC,IAAI,CAAC1E,OAAO,CAACmE,IAAI,EACb,OAAO,EAAE;IACb,OAAOnE,OAAO,CAACmE,IAAI,CAACZ,GAAG,CAAEoB,GAAG,IAAK;MAC7B,IAAI,OAAOA,GAAG,KAAK,QAAQ,IAAI,OAAO,IAAIA,GAAG,EAAE;QAAA,IAAAC,UAAA;QAC3C5E,OAAO,CAACoE,aAAa,CAACO,GAAG,CAACnB,KAAK,CAAC,IAAAoB,UAAA,GAAGD,GAAG,CAACE,KAAK,cAAAD,UAAA,cAAAA,UAAA,GAAID,GAAG,CAACnB,KAAK;QACzD,OAAOmB,GAAG,CAACnB,KAAK;MACpB;MACA,OAAOmB,GAAG;IACd,CAAC,CAAC;EACN;EACA,SAASG,wBAAwBA,CAAA,EAAG;IAChC,IAAI,CAAC9E,OAAO,CAACmE,IAAI,EACb,OAAO,EAAE;IACb,OAAOnE,OAAO,CAACmE,IAAI,CAACY,OAAO,CAACC,IAAI,IAAI;MAChC,IAAI,OAAOA,IAAI,KAAK,QAAQ,EAAE;QAC1B;QACA,OAAO,EAAE;MACb,CAAC,MACI,IAAIA,IAAI,aAAJA,IAAI,eAAJA,IAAI,CAAEC,aAAa,EAAE;QAC1B;QACA,OAAOD,IAAI,CAACxB,KAAK;MACrB;MACA;MACA,OAAO,EAAE;IACb,CAAC,CAAC;EACN;EACA;AACJ;AACA;AACA;EACI,SAAS0B,oBAAoBA,CAACjE,IAAI,EAAE;IAChC,MAAMkE,iBAAiB,GAAGL,wBAAwB,CAAC,CAAC;IACpD,MAAMM,UAAU,GAAGV,yBAAyB,CAAC,CAAC;IAC9C,MAAMzB,UAAU,GAAGjC,gBAAgB,CAACC,IAAI,CAAC;IACzC,MAAMoE,SAAS,GAAGlE,cAAc,CAAC8B,UAAU,CAAC;IAC5C,IAAIjD,OAAO,CAACmE,IAAI,EAAE;MACdnE,OAAO,CAACmE,IAAI,GAAGiB,UAAU;MACzB,MAAME,WAAW,GAAGF,UAAU,CAACL,OAAO,CAAEQ,eAAe,IAAK;QACxD;QACA,IAAI,CAACJ,iBAAiB,CAACZ,QAAQ,CAACgB,eAAe,CAAC,EAAE;UAC9C,OAAOA,eAAe;QAC1B;QACA;QACA,MAAMC,OAAO,GAAG,EAAE;QAClB,MAAM3C,KAAK,GAAG,IAAI3C,MAAM,KAAA4C,MAAA,CAAKyC,eAAe,CAAE,CAAC;QAC/C,KAAK,MAAME,WAAW,IAAIJ,SAAS,EAAE;UACjC,IAAIE,eAAe,KAAKE,WAAW,IAAIA,WAAW,CAAC1C,KAAK,CAACF,KAAK,CAAC,EAAE;YAC7D2C,OAAO,CAACE,IAAI,CAACD,WAAW,CAAC;UAC7B;QACJ;QACA,OAAOD,OAAO;MAClB,CAAC,CAAC;MACF,IAAI,CAACxF,OAAO,CAACU,YAAY,EAAE;QACvB,MAAMiF,QAAQ,GAAGpD,kBAAkB,CAAC+C,WAAW,CAAC;QAChD,OAAOtC,gBAAgB,CAAC2C,QAAQ,CAAC;MACrC;IACJ;IACA,MAAMA,QAAQ,GAAGpD,kBAAkB,CAAC8C,SAAS,CAAC;IAC9C,OAAOrC,gBAAgB,CAAC2C,QAAQ,CAAC;EACrC;EACA;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACI,SAASC,wBAAwBA,CAACvC,MAAM,EAAqB;IAAA,IAAnBwC,SAAS,GAAAC,SAAA,CAAAxD,MAAA,QAAAwD,SAAA,QAAAvH,SAAA,GAAAuH,SAAA,MAAG,KAAK;IACvD,IAAI9F,OAAO,CAACU,YAAY,EAAE;MACtB,MAAMqF,qBAAqB,GAAG1C,MAAM,CAAC2C,OAAO,CAAC1D,MAAM;MACnD;MACAe,MAAM,CAACC,YAAY,CAAC2C,OAAO,CAAEC,WAAW,IAAK;QACzC7C,MAAM,CAAC2C,OAAO,GAAGjG,KAAK,CAACoG,MAAM,CAAC9C,MAAM,CAAC2C,OAAO,EAAEE,WAAW,CAAC;MAC9D,CAAC,CAAC;MACF,MAAM5C,YAAY,GAAG4B,oBAAoB,CAAC7B,MAAM,CAAC2C,OAAO,CAAC;MACzD3C,MAAM,CAACC,YAAY,GAAGA,YAAY;MAClC;MACA,IAAIyC,qBAAqB,KAAK1C,MAAM,CAAC2C,OAAO,CAAC1D,MAAM,EAAE;QACjD,OAAOsD,wBAAwB,CAACvC,MAAM,CAAC;MAC3C;MACA;MACA;MACA;MACA,IAAI,CAACwC,SAAS,EAAE;QACZ,OAAOD,wBAAwB,CAACvC,MAAM,EAAE,IAAI,CAAC;MACjD;MACA;MACA,IAAIrD,OAAO,CAACmE,IAAI,EAAE;QACd,MAAMiC,kBAAkB,GAAG1B,yBAAyB,CAAC,CAAC;QACtDrB,MAAM,CAACC,YAAY,GAAGf,kBAAkB,CAAC6D,kBAAkB,CAAC;MAChE;MACA,OAAO/C,MAAM;IACjB;IACA,OAAOA,MAAM;EACjB;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,SAASgD,cAAcA,CAAChD,MAAM,EAAE;IAC5BA,MAAM,CAACiD,YAAY,GAAGjD,MAAM,CAAC2C,OAAO,CAACzC,GAAG,CAAEgD,MAAM,IAAK;MACjD;MACA,MAAMC,eAAe,GAAGC,uBAAuB,CAACF,MAAM,EAAElD,MAAM,CAACC,YAAY,CAAC;QAC5E;QACAoD,mBAAmB,GAAGF,eAAe,CAACjD,GAAG,CAAEoD,UAAU,IAAK;UACtDA,UAAU,GAAGC,oBAAoB,CAACD,UAAU,CAAC;UAC7CA,UAAU,GAAGE,mBAAmB,CAACF,UAAU,CAAC;UAC5C,IAAIG,WAAW,GAAGxG,iBAAiB,GAAGA,iBAAiB,CAACqG,UAAU,EAAEI,wBAAwB,CAAC,GAAGA,wBAAwB,CAACJ,UAAU,CAAC;UACpIG,WAAW,GAAG9C,yBAAyB,CAAC8C,WAAW,CAAC;UACpD,OAAOA,WAAW;QACtB,CAAC,CAAC;MACF;MACA,OAAOE,wBAAwB,CAACN,mBAAmB,CAAC;IACxD,CAAC,CAAC,CAAC9C,IAAI,CAAC5D,OAAO,CAACG,SAAS,CAAC8G,GAAG,CAAC;IAC9B,OAAO5D,MAAM;EACjB;EACA;AACJ;AACA;EACI,SAAS6D,4CAA4CA,CAACC,gBAAgB,EAAE;IACpE,MAAMC,wBAAwB,GAAGrH,KAAK,CAACsH,iBAAiB,CAACF,gBAAgB,CAAC;IAC1E;IACA,IAAI,CAACA,gBAAgB,CAAC7E,MAAM,IAAI,CAAC8E,wBAAwB,CAAC9E,MAAM,EAAE;MAC9D,OAAOtC,OAAO,CAACsH,eAAe,IAAI,EAAE;IACxC,CAAC,MACI,IAAIF,wBAAwB,CAAC9E,MAAM,KAAK,CAAC,EAAE;MAC5C;MACA;MACA,OAAO8E,wBAAwB,CAAC,CAAC,CAAC,CAAC,CAAC;IACxC;IACA,OAAOD,gBAAgB;EAC3B;EACA;AACJ;AACA;EACI,SAASV,uBAAuBA,CAACF,MAAM,EAAEgB,MAAM,EAAE;IAC7C,MAAMC,YAAY,GAAG,EAAE;IACvBD,MAAM,CAACtB,OAAO,CAAEzC,KAAK,IAAK;MACtB,IAAI2D,gBAAgB,GAAG,CAAC,CAAC,EAAExH,UAAU,CAAC8H,YAAY,EAAElB,MAAM,EAAE/C,KAAK,CAAC;MAClE,IAAI,CAACzD,KAAK,CAAC2H,WAAW,CAAC1H,OAAO,CAACsH,eAAe,CAAC,IAAIvH,KAAK,CAAC4H,YAAY,CAACR,gBAAgB,CAAC,EAAE;QACrFA,gBAAgB,GAAGnH,OAAO,CAACsH,eAAe;MAC9C,CAAC,MACI,IAAItH,OAAO,CAACS,kBAAkB,IAAImH,KAAK,CAACC,OAAO,CAACV,gBAAgB,CAAC,EAAE;QACpEA,gBAAgB,GAAGD,4CAA4C,CAACC,gBAAgB,CAAC;MACrF;MACAK,YAAY,CAAC9B,IAAI,CAACyB,gBAAgB,CAAC;IACvC,CAAC,CAAC;IACF,OAAOK,YAAY;EACvB;EACA;AACJ;AACA;EACI,SAAST,wBAAwBA,CAACJ,UAAU,EAAE;IAC1C,MAAMmB,MAAM,GAAGnB,UAAU,YAAYoB,IAAI,CAAC,CAAC;IAC3C,IAAIpB,UAAU,KAAK,IAAI,IAAIiB,KAAK,CAACC,OAAO,CAAClB,UAAU,CAAC,IAAI,OAAOA,UAAU,KAAK,QAAQ,IAAI,CAACmB,MAAM,EAAE;MAC/F,OAAOE,IAAI,CAACC,SAAS,CAACtB,UAAU,CAAC;IACrC,CAAC,MACI,IAAI,OAAOA,UAAU,KAAK,WAAW,EAAE;MACxC,OAAO,WAAW;IACtB,CAAC,MACI,IAAImB,MAAM,IAAI9H,OAAO,CAACkI,oBAAoB,EAAE;MAC7C,OAAOvB,UAAU,CAACwB,WAAW,CAAC,CAAC;IACnC,CAAC,MACI;MACD,OAAO,CAACnI,OAAO,CAACoI,eAAe,GAAGzB,UAAU,CAAC0B,QAAQ,CAAC,CAAC,GAAG1B,UAAU,CAAC2B,cAAc,CAAC,CAAC;IACzF;EACJ;EACA;AACJ;AACA;EACI,SAAS1B,oBAAoBA,CAACD,UAAU,EAAE;IACtC,IAAI3G,OAAO,CAACuI,eAAe,EAAE;MACzB,IAAIX,KAAK,CAACC,OAAO,CAAClB,UAAU,CAAC,EAAE;QAC3B,OAAOA,UAAU,CAACpD,GAAG,CAACqD,oBAAoB,CAAC;MAC/C,CAAC,MACI,IAAI,OAAOD,UAAU,KAAK,QAAQ,EAAE;QACrC,OAAOA,UAAU,CAAChD,IAAI,CAAC,CAAC;MAC5B;MACA,OAAOgD,UAAU;IACrB;IACA,OAAOA,UAAU;EACrB;EACA;AACJ;AACA;AACA;AACA;AACA;EACI,SAASE,mBAAmBA,CAACF,UAAU,EAAE;IACrC,IAAI3G,OAAO,CAAC6G,mBAAmB,EAAE;MAC7B,IAAIe,KAAK,CAACC,OAAO,CAAClB,UAAU,CAAC,EAAE;QAC3B,OAAOA,UAAU,CAACpD,GAAG,CAACsD,mBAAmB,CAAC;MAC9C,CAAC,MACI,IAAI,OAAOF,UAAU,KAAK,QAAQ,IAAI,CAAC5G,KAAK,CAACyI,QAAQ,CAAC7B,UAAU,CAAC,EAAE;QACpE,OAAOA,UAAU,CAAClC,OAAO,CAAC,gBAAgB,EAAE,EAAE,CAAC;MACnD;MACA,OAAOkC,UAAU;IACrB;IACA,OAAOA,UAAU;EACrB;EACA;AACJ;AACA;AACA;AACA;EACI,SAAS3C,yBAAyBA,CAAC2C,UAAU,EAAE;IAC3C,MAAM8B,aAAa,GAAGzI,OAAO,CAACG,SAAS,CAACC,IAAI;IAC5C;IACA,IAAIuG,UAAU,CAACpC,QAAQ,CAACvE,OAAO,CAACG,SAAS,CAACC,IAAI,CAAC,EAAE;MAC7C;MACAuG,UAAU,GAAGA,UAAU,CAAClC,OAAO,CAACxE,uBAAuB,EAAEwI,aAAa,GAAGA,aAAa,CAAC;IAC3F;IACA;IACA;IACA,IAAI9B,UAAU,CAACpC,QAAQ,CAACvE,OAAO,CAACG,SAAS,CAACqD,KAAK,CAAC,IAC5CmD,UAAU,CAACpC,QAAQ,CAACvE,OAAO,CAACG,SAAS,CAACC,IAAI,CAAC,IAC3CuG,UAAU,CAAC5D,KAAK,CAAC1C,eAAe,CAAC,IACjCL,OAAO,CAAC0I,YAAY,KAAK/B,UAAU,KAAK,MAAM,IAAIA,UAAU,KAAK,OAAO,CAAC,EAAE;MAC3E;MACAA,UAAU,GAAG8B,aAAa,GAAG9B,UAAU,GAAG8B,aAAa;IAC3D;IACA,OAAO9B,UAAU;EACrB;EACA;AACJ;AACA;EACI,SAASK,wBAAwBA,CAAC2B,iBAAiB,EAAE;IACjD,OAAOA,iBAAiB,CAAC/E,IAAI,CAAC5D,OAAO,CAACG,SAAS,CAACqD,KAAK,CAAC;EAC1D;EACA;EACA;AACJ;AACA;AACA;AACA;EACI,SAASoF,yBAAyBA,CAACvF,MAAM,EAAE;IACvC,MAAMgB,MAAM,GAAGhB,MAAM,CAACgB,MAAM;MAAE2B,OAAO,GAAG3C,MAAM,CAACiD,YAAY;MAC3D;MACAuC,GAAG,GAAG,CAAC7I,OAAO,CAAC8I,QAAQ,GAAGhJ,WAAW,CAACgJ,QAAQ,GAAG,EAAE,KAC9C9I,OAAO,CAAC8D,aAAa,GAAGO,MAAM,GAAGrE,OAAO,CAACG,SAAS,CAAC8G,GAAG,GAAG,EAAE,CAAC,GAC7DjB,OAAO;IACX,OAAO6C,GAAG;EACd;EACA;EACA;AACJ;AACA;EACI,SAASE,OAAOA,CAAC9H,IAAI,EAAE;IACnB;IACA,IAAIlB,KAAK,CAACiJ,QAAQ,CAAC/H,IAAI,CAAC,IAAI,CAACA,IAAI,CAACqB,MAAM,EAAE;MACtCrB,IAAI,GAAG,CAACA,IAAI,CAAC,CAAC,CAAC;IACnB;IACA;IACA,MAAMqC,YAAY,GAAG;MACjBA,YAAY,EAAE4B,oBAAoB,CAACjE,IAAI,CAAC;MACxC+E,OAAO,EAAE/E,IAAI;MACboD,MAAM,EAAE,EAAE;MACViC,YAAY,EAAE;IAClB,CAAC;IACD,MAAM2C,QAAQ,GAAGrD,wBAAwB,CAACtC,YAAY,CAAC;IACvD,MAAM+B,SAAS,GAAGgB,cAAc,CAAC4C,QAAQ,CAAC;IAC1C,MAAMC,OAAO,GAAGrF,gBAAgB,CAACwB,SAAS,CAAC;IAC3C,MAAM8D,OAAO,GAAG/F,gBAAgB,CAAC8F,OAAO,CAAC;IACzC,MAAME,SAAS,GAAGnF,iBAAiB,CAACkF,OAAO,CAAC;IAC5C,OAAOP,yBAAyB,CAACQ,SAAS,CAAC;EAC/C;EACA,OAAO;IACHL;EACJ,CAAC;AACL,CAAC;AACDtJ,OAAO,CAACC,QAAQ,GAAGA,QAAQ","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}